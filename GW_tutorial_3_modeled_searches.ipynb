{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oe9SQUuVgkEy",
    "tags": []
   },
   "source": [
    "### GW tutorial 3: Generation of data and matched filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Melissa Lopez\n",
    "\n",
    "Email: m.lopez@uu.nl"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NeSv96NLLDw",
    "outputId": "2c5a816d-0e6e-42ca-82eb-e7c2be870f8d",
    "ExecuteTime": {
     "end_time": "2026-02-10T22:04:44.941526525Z",
     "start_time": "2026-02-10T22:04:44.887116182Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "from pycbc.catalog import Merger\n",
    "import pycbc.psd, pycbc.noise\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pycbc.waveform import get_td_waveform\n",
    "from pycbc.detector import Detector\n",
    "import random"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycbc'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m get_ipython()\u001B[38;5;241m.\u001B[39mrun_line_magic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmatplotlib\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minline\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpycbc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcatalog\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Merger\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpycbc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpsd\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mpycbc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnoise\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpylab\u001B[39;00m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pycbc'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we have plotted the PSD of different detectors. Some PSDs are from previous runs (O3), while some others are the design sensitivity of future detectors.\n",
    "\n",
    "The PSD characterizes the noise of the detector, so we can generate detector noise accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:** Load the `aligo_O4high.txt` PSD to [generate](https://pycbc.org/pycbc/latest/html/pycbc.noise.html#pycbc.noise.gaussian.noise_from_psd) some Gaussian data.\n",
    "\n",
    "_Hint:_ Minimum frequency is 10Hz, sampling rate 4096 Hz and we want 20s of duration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Adding the known constants - changed min_freq to 12 Hz as presented in the next problems\n",
    "sample_rate = 4096\n",
    "min_freq = 12\n",
    "dur=20\n",
    "\n",
    "# Finding delta f, t, total length and the psd length (flen)\n",
    "dlt_f=1/dur\n",
    "dlt_t=1/sample_rate\n",
    "length=int(dur/dlt_t)\n",
    "flen=int(sample_rate / 2 / dlt_f) + 1\n",
    "\n",
    "#The equations and the code were taken from https://pycbc.org/pycbc/latest/html/psd.html: Estimating the PSD of a time series\n",
    "\n",
    "data = pycbc.psd.from_txt('/home/marius/Downloads/aligo_O4high.txt', flen, dlt_f,  min_freq)\n",
    "\n",
    "noise_data = pycbc.noise.gaussian.noise_from_psd(length, dlt_t, psd=data)\n",
    "\n",
    "print(data,'\\n')\n",
    "print(len(data),'\\n')\n",
    "print(noise_data)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see. the generated noise is \"coloured\" according to the detector noise. Now, we would like to add a simulated gravitational wave signal in our detector noise. \n",
    "\n",
    "**Exercise 2:** Using [this function](https://pycbc.org/pycbc/latest/html/pycbc.waveform.html#pycbc.waveform.waveform.get_td_waveform) to generate waveforms in time domain, provide the plus and cross polarization of a binary black hole merger of $m_{1} = m_{2} = 50$ at 2000 Mpc. Use the waveform approximant \"IMRPhenomD\". How does the waveform amplitude compare to the detector noise?\n",
    "\n",
    "The waveform comes from the source, but it needs to be projected in the detector. [Project](https://pycbc.org/pycbc/latest/html/pycbc.detector.html#pycbc.detector.ground.Detector.project_wave) the waveform on LIGO Livingston (L1) at random sky-location and polarization. You can specify your detector with [this](https://pycbc.org/pycbc/latest/html/pycbc.detector.html#pycbc.detector.ground.Detector) function. How does the waveform change because of this projection?\n",
    "\n",
    "_Hint:_ Right ascension range is $[0, 2\\pi]$, declination is $[-2\\pi, 2\\pi]$ and polarization is $[0, 2\\pi]$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Making the signal\n",
    "hp,hc=pycbc.waveform.waveform.get_td_waveform(template = None, mass1 = 50, mass2 = 50, distance = 2000, delta_t = dlt_t, approximant=\"IMRPhenomD\", f_lower = min_freq)\n",
    "\n",
    "# Testing the structure of tha data\n",
    "print(hp,'\\n',hc)\n",
    "print(len(hp),len(hc))\n",
    "\n",
    "print(hp.sample_times,noise_data.sample_times)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How does the waveform amplitude compare to the detector noise?\n",
    "\n",
    "As it can be seen in from the graphs below, it is impossible to get any information out of the detector noise. This is because the detector signal is weaker by 2 orders of magnitude compared with the noise.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "#print(hp.sample_times,noise_data.sample_times)\n",
    "\n",
    "#we change the start time for hp and hc so to add them to the data\n",
    "hp.start_time=4\n",
    "hc.start_time=4\n",
    "\n",
    "dt = noise_data.copy()\n",
    "\n",
    "#print(len(dt),len(hp))\n",
    "\n",
    "#we add hp to the data\n",
    "start_index = length - len(hp)\n",
    "print(start_index)\n",
    "dt[start_index:start_index+len(hp)] += hp\n",
    "\n",
    "\n",
    "#Everything is plotted\n",
    "plt.plot(hp.sample_times, hp, label=\"Signal\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(dt.sample_times, dt, label=\"Noise data with the added signal\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(len(hp),len(noise_data),length)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How does the waveform change because of this projection?\n",
    "\n",
    "As it can be seen in the graph below the projected form has changed in size, shrinking."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "detector = Detector(\"L1\")\n",
    "\n",
    "#We get random numbers\n",
    "ra = random.uniform(0, 2 * np.pi)\n",
    "dec = random.uniform(-np.pi * 2, np.pi * 2)\n",
    "polar = random.uniform(0, 2 * np.pi)\n",
    "\n",
    "\n",
    "#the given function is used\n",
    "prj = detector.project_wave(hp, hc, ra = ra, dec = dec, polarization = polar)\n",
    "\n",
    "print(prj.delta_f)\n",
    "#the comparison between hc and f is done\n",
    "plt.plot(hc.sample_times, hc, label=\"Old waveform\")\n",
    "plt.plot(prj.sample_times, prj, label=\"Projection\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Exercise 2:** From before our detector noise is 20s long. Add the GW into noise after 5s. We also need to get the first 4s to estimate the PSD in the next excercise. Make an overlaid plot with the total data, the portion of data where the GW is added and the data needed to estimate the PSD.\n",
    "\n",
    "_Bonus:_ Can you also plot the GW signal?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "_This part was partially done with the start at 4 sec in the last exercise, a similar procedure will be used here_"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:03:34.153935902Z",
     "start_time": "2026-02-10T22:03:34.125878067Z"
    }
   },
   "source": [
    "#print(hp.sample_times,noise_data.sample_times)\n",
    "\n",
    "# We change the start time of prj so to add them to the data\n",
    "noise_data.start_time=0\n",
    "prj.start_time=noise_data.start_time + 5\n",
    "\n",
    "dt = noise_data.copy() # Make copy to conserve the original noise data\n",
    "\n",
    "#print(len(dt),len(hp))\n",
    "\n",
    "# We add projection to the noise data\n",
    "\n",
    "#print(noise_data.start_time)\n",
    "\n",
    "start = int(5 / dlt_t)\n",
    "\n",
    "dt[start : start + len(prj[ : len(dt) - start])] += prj[ : len(dt) - start]\n",
    "\n",
    "# The fist 4 sec data str is made\n",
    "f4s = noise_data[:int(4/dlt_t)]\n",
    "\n",
    "print(dt.delta_f)\n",
    "\n",
    "#GW signal\n",
    "plt.plot(prj.sample_times, prj, label=\"GW\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Noise + GW signal\n",
    "plt.plot(dt.sample_times, dt, label=\"Noise and GW signal\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#The full plot with all that data\n",
    "plt.plot(dt.sample_times, dt, label=\"Noise and GW signal\")\n",
    "plt.plot(noise_data.sample_times, noise_data, label=\"Noise data\")\n",
    "plt.plot(f4s.sample_times, f4s, label=\"The first 4 second of the noise data\")\n",
    "plt.plot(prj.sample_times, prj, label=\"GW signal\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noise_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#print(hp.sample_times,noise_data.sample_times)\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# We change the start time of prj so to add them to the data\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[43mnoise_data\u001B[49m\u001B[38;5;241m.\u001B[39mstart_time\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      5\u001B[0m prj\u001B[38;5;241m.\u001B[39mstart_time\u001B[38;5;241m=\u001B[39mnoise_data\u001B[38;5;241m.\u001B[39mstart_time \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m5\u001B[39m\n\u001B[1;32m      7\u001B[0m dt \u001B[38;5;241m=\u001B[39m noise_data\u001B[38;5;241m.\u001B[39mcopy() \u001B[38;5;66;03m# Make copy to conserve the original noise data\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'noise_data' is not defined"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** In a proper search we do not really have the PSD handy. We want to estimate the PSD with Welch's method (see [here](https://ccrma.stanford.edu/~jos/sasp/Welch_s_Method.html) for details), but we want to use the 4s of the beginning where the GW is not present using [this function](https://pycbc.org/pycbc/latest/html/pycbc.psd.html#pycbc.psd.estimate.welch). Plot the estimated PSD. Note that before we used a dummy whitening, and this one is a bit better.\n",
    "\n",
    "What is the $\\Delta_f$ of the estimated PSD? What is $\\Delta_f$ of the data we want to whiten to see the GW signal?\n",
    "\n",
    "_Hint:_ `seg_stride (int)` is usually half of `seg_len`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Make the welch data structure\n",
    "welch = pycbc.psd.estimate.welch(f4s, seg_len = sample_rate * 4, seg_stride = sample_rate * 2, window='hann', avg_method='median', num_segments=None, require_exact_data_fit=False)\n",
    "\n",
    "#Noise + GW signal\n",
    "plt.loglog(welch.sample_frequencies, welch, label=\"Noise and GW signal\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Show the delta f\n",
    "print('The delta f of the estimated PSD is:', welch.delta_f)\n",
    "print('The delta f of the data we want to whiten:', dt.delta_f)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the PSD we need to interpolate it to match our data and then limit the filter length of 1 / PSD. After this, we can directly use this PSD to filter the data. Since the data has been highpassed above 12 Hz, and will have low values below this we need to informat the function to not include frequencies below this frequency. \n",
    "\n",
    "**Exercise 4:** Use the functions [interpolate](https://pycbc.org/pycbc/latest/html/pycbc.psd.html#pycbc.psd.estimate.interpolate) and [inverse_spectrum_truncation](https://pycbc.org/pycbc/latest/html/pycbc.psd.html#pycbc.psd.estimate.inverse_spectrum_truncation) to achieve a proper formatting of the PSD.\n",
    "\n",
    "_Hint:_ `max_filter_len (int)` is $4 \\times$ sampling_rate. Note that the original PSD has a minimum frequency of 12Hz."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Interpolate and truncate the welch data\n",
    "it_welch = pycbc.psd.estimate.interpolate(welch, dlt_f, length=None)\n",
    "trc_it_welch = pycbc.psd.estimate.inverse_spectrum_truncation(it_welch, max_filter_len = 4 * sample_rate, low_frequency_cutoff=12, trunc_method=None)\n",
    "\n",
    "\n",
    "# Test teh new data structures\n",
    "print(welch)\n",
    "print(it_welch)\n",
    "print(trc_it_welch,'\\n')\n",
    "print(len(dt),len(welch),len(it_welch),len(trc_it_welch),'\\n')\n",
    "\n",
    "print(dt.delta_f,trc_it_welch.delta_f,)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the PSD is ready, we can whiten the data. Before we used a PyCBC function, but mathematically this is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\tilde{d_w}(f) = \\tilde{d}(f)/S_{n}^{-1/2}(f)\n",
    "\\end{equation}\n",
    "where $\\tilde{d}$ and $\\tilde{d_w}(f)$ are the Fourier transform of the coloured data and whitened data, respectively.\n",
    "\n",
    "**Exercise 5:** Whiten the data using the interpolated PSD. Crop 5s at the beginning and the end to avoid border effects (_aliasing_) and bandpass it as in the previous exercise. Can you see the GW signal?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As the GW signal for my data peeks at time point 16 I changed the border cutting to 12 and 18.\n",
    "\n",
    "Yes, now the GW signal is visible!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#As the psd is presented in frequency we need to change our data from time series to frequency series\n",
    "f_dt = dt.to_frequencyseries()\n",
    "\n",
    "#The desired eq\n",
    "wh_dt = f_dt / np.sqrt(trc_it_welch)\n",
    "\n",
    "#Going back to time series\n",
    "wh_dt = wh_dt.to_timeseries()\n",
    "\n",
    "#Cutting the borders\n",
    "wh_dt = wh_dt[int(12/wh_dt.delta_t):int(18/wh_dt.delta_t)]\n",
    "\n",
    "#Bandoassing the data (my ideas)\n",
    "wh_low_data = wh_dt.lowpass_fir(frequency=50, order=512)\n",
    "wh_all_data = wh_low_data.highpass_fir(frequency=20, order=512)\n",
    "\n",
    "\n",
    "#My own play with the data\n",
    "plt.plot(wh_all_data.sample_times, wh_all_data, label=\"Whiten data between 50 and 20 HZ\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Bandoassing the data as presented in the lab\n",
    "wh_low_data_last = wh_dt.lowpass_fir(frequency=250, order=512)\n",
    "wh_all_data_last =  wh_low_data_last.highpass_fir(frequency=30, order=512)\n",
    "\n",
    "#The data plotting\n",
    "plt.plot(wh_all_data_last.sample_times, wh_all_data_last, label=\"Whiten data between 250 and 30 HZ\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Strain\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we buried a GW signal  $h(t)$ in stationary and Gaussian noise $n(t)$ with zero mean, such that $s(t) = h(t) + n(t)$. Given the optimal filter  $K(t)$, \n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{s} = \\int_{-\\infty}^{\\infty}  K(t)s(t) dt = \\int_{-\\infty}^{\\infty} \\tilde{K}(f)^{*}\\tilde{s}(f) df, \\quad \\text{ where }  \\tilde{s}(f) = \\int_{-\\infty}^{\\infty} s(t)e^{-2 \\pi i ft}dt\n",
    "\\end{equation}\n",
    "\n",
    "where $\\hat{s}$ is the filtered value of $s(t)$, $^*$ represents the complex conjugate, and $\\tilde{\\cdot }\\ $ the Fourier transform. \n",
    "\n",
    "The detection statistic that is maximised by the optimal filter $K(t)$  will be the SNR, defined as $\\rho = S/N$. $S$ is the expected value of $\\hat{s}$ when $h(t) \\neq 0$, while $N$ is the squared root of the noise variance when $h(t) =0$. It can be demonstrated that the optimal filter $K(t)$ is the model of the GW signal itself, known as _template_.\n",
    "\n",
    "The fundamental modelled detection technique is called \"matched filtering\", since the filter function is chosen to \"match\" the signal we are looking for. We can write the SNR between an unknown time series $s(t)$ and the template $h_{m}$ as\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho =  4 \\text{Re} \\int_{0}^{\\infty} \\frac{\\tilde{s}^{*}(f)}{S_{n}(f)} \\tilde{h_{m}}(f) df. \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "**Exercise 6:** Use the [matched_filter](https://pycbc.org/pycbc/latest/html/pycbc.filter.html#pycbc.filter.matchedfilter.matched_filter) function to filter the coloured data with the template. Crop the SNR time series 5s at each side and plot it together with the whitened data. Where is the GW signal? Note that the y-axis of the whitened data is _amplitude_ and the y-axis of the SNR timeseries is _SNR_.\n",
    "\n",
    "How much is the maximum of the absolute value of the SNR time series? If it is larger than 5 it will generate a \"trigger\" for further analysis. Will the trigger be generated?\n",
    "\n",
    "Note that the parameter space of GW signals is vast, so to find these signals, we will need to create a template bank and do this process for thousands of templates. Then, this becomes a high-performance computing problem!\n",
    "\n",
    "_Hint_: you need to [resize](https://pycbc.org/pycbc/latest/html/pycbc.types.html#pycbc.types.array.Array.resize) the template and use [cyclic_time_shift](https://pycbc.org/pycbc/latest/html/pycbc.types.html#pycbc.types.frequencyseries.FrequencySeries.cyclic_time_shift)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# We will take hp as the template and processed it\n",
    "template = prj.copy()\n",
    "template.resize(len(dt))  # Such to work on the data\n",
    "\n",
    "template = template.to_frequencyseries() # Change in frequency\n",
    "template = template.cyclic_time_shift(template.start_time)\n",
    "\n",
    "# Make the snr\n",
    "snr = pycbc.filter.matchedfilter.matched_filter(template, dt, psd = trc_it_welch, low_frequency_cutoff = 12)\n",
    "\n",
    "# Crop it at the\n",
    "snr = snr.crop(12, 2)\n",
    "\n",
    "# Printing the information\n",
    "abs_snr = np.abs(snr)\n",
    "imax = abs_snr.numpy().argmax()\n",
    "t_peak = snr.sample_times[imax]\n",
    "\n",
    "print(\"Peak time (s):\", float(t_peak))\n",
    "print(\"Max |SNR|:\", float(abs_snr[imax]))\n",
    "print(\"Trigger generated? (|SNR|>5):\", bool(abs_snr[imax] > 5))\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(wh_all_data_last.sample_times, wh_all_data_last)\n",
    "plt.plot(snr.sample_times, snr)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Whitened strain\")\n",
    "plt.axvline(t_peak, linestyle = \"--\")\n",
    "plt.title(\"Whitened data and matched-filter SNR\")\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSYU6DFeFcpt"
   },
   "source": [
    "Good job arriving at the end of the tutorial! This was a small peak at GW data analysis that I hope you found interesting. \n",
    "\n",
    "There is a bonus track exercise if you are bored, but we can also have a chat about some more GW data analysis if you prefer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gengli_env",
   "language": "python",
   "name": "gengli_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
